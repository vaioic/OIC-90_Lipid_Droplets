{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ba4b9d-62d2-463e-9fb9-ba7dfcb9e3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, unicode_literals, absolute_import, division\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.rcParams[\"image.interpolation\"] = 'none'\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from tifffile import imread\n",
    "from csbdeep.utils import Path, download_and_extract_zip_file\n",
    "\n",
    "from stardist import relabel_image_stardist3D, Rays_GoldenSpiral, calculate_extents\n",
    "from stardist import fill_label_holes, random_label_cmap\n",
    "from stardist.matching import matching_dataset\n",
    "\n",
    "np.random.seed(42)\n",
    "lbl_cmap = random_label_cmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eae382f-8225-4268-b25e-921f16483615",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_and_extract_zip_file(\n",
    "    url       = 'https://github.com/stardist/stardist/releases/download/0.3.0/demo3D.zip',\n",
    "    targetdir = 'data',\n",
    "    verbose   = 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4b1b0f-e020-4d2b-81b0-578504927bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sorted(glob('E:/Lien_Lab/Sam/OIC-40_Lipid_Droplet/lipid_data/train/images/*.tif'))\n",
    "Y = sorted(glob('E:/Lien_Lab/Sam/OIC-40_Lipid_Droplet/lipid_data/train/masks/*.tif'))\n",
    "assert all(Path(x).name==Path(y).name for x,y in zip(X,Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24924aa1-5a0c-4fb8-afe9-9628f63ad698",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d96cddb-0b13-4e22-9d7a-fe291abf80d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = X[:10], Y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1546979-d8db-40a7-a55a-77724fb35cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(map(imread,X))\n",
    "Y = list(map(imread,Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe81cc45-04c1-4761-b917-705e9e6525be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac40a91-b40e-4fcf-b4d5-bb49a881c642",
   "metadata": {},
   "outputs": [],
   "source": [
    "extents = calculate_extents(Y)\n",
    "anisotropy = tuple(np.max(extents) / extents)\n",
    "print('empirical anisotropy of labeled objects = %s' % str(anisotropy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cd9662-8082-4861-9f93-5c2587d5cd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "img, lbl = X[i], fill_label_holes(Y[i])\n",
    "assert img.ndim in (3,4)\n",
    "# assumed axes ordering of img and lbl is: ZYX(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c66f418-8e56-4da8-99ba-f372eeedd532",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "z = img.shape[0] // 2\n",
    "y = img.shape[1] // 2\n",
    "plt.subplot(121); plt.imshow(img[z],cmap='gray');   plt.axis('off'); plt.title('Raw image (XY slice)')\n",
    "plt.subplot(122); plt.imshow(lbl[z],cmap=lbl_cmap); plt.axis('off'); plt.title('GT labels (XY slice)')\n",
    "plt.figure(figsize=(16,10))\n",
    "plt.subplot(121); plt.imshow(img[:,y],cmap='gray');   plt.axis('off'); plt.title('Raw image (XZ slice)')\n",
    "plt.subplot(122); plt.imshow(lbl[:,y],cmap=lbl_cmap); plt.axis('off'); plt.title('GT labels (XZ slice)')\n",
    "None;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e416ef7-a61e-4682-827c-ce5fb83ed85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruction_scores(n_rays, anisotropy):\n",
    "    scores = []\n",
    "    for r in tqdm(n_rays):\n",
    "        rays = Rays_GoldenSpiral(r, anisotropy=anisotropy)\n",
    "        Y_reconstructed = [relabel_image_stardist3D(lbl, rays) for lbl in Y]\n",
    "        mean_iou = matching_dataset(Y, Y_reconstructed, thresh=0, show_progress=False).mean_true_score\n",
    "        scores.append(mean_iou)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0ec9c3-3ee2-4634-88b5-906b4615c800",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rays = [8, 16, 32, 64, 96, 128]\n",
    "scores_iso   = reconstruction_scores(n_rays, anisotropy=None)\n",
    "scores_aniso = reconstruction_scores(n_rays, anisotropy=anisotropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3be4ab-f493-4a20-bb53-44f9f3edc9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(n_rays, scores_iso,   'o-', label='Isotropic')\n",
    "plt.plot(n_rays, scores_aniso, 'o-', label='Anisotropic')\n",
    "plt.xlabel('Number of rays for star-convex polyhedra')\n",
    "plt.ylabel('Reconstruction score (mean intersection over union)')\n",
    "plt.legend()\n",
    "None;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee5a3e9-d94b-48e1-bf3c-beef2e28fb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,3, figsize=(16,11))\n",
    "for a,r in zip(ax.flat,n_rays):\n",
    "    z = lbl.shape[0] // 2\n",
    "    rays = Rays_GoldenSpiral(r, anisotropy=None)\n",
    "    a.imshow(relabel_image_stardist3D(lbl, rays)[z], cmap=lbl_cmap)\n",
    "    a.set_title('Reconstructed (XY slice, %d rays)' % r)\n",
    "    a.axis('off')\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0665bf-4ce3-4a18-ab6a-9a4987f07e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Training StarDist Model##\n",
    "from __future__ import print_function, unicode_literals, absolute_import, division\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.rcParams[\"image.interpolation\"] = 'none'\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from tifffile import imread\n",
    "from csbdeep.utils import Path, normalize\n",
    "\n",
    "from stardist import fill_label_holes, random_label_cmap, calculate_extents, gputools_available\n",
    "from stardist import Rays_GoldenSpiral\n",
    "from stardist.matching import matching, matching_dataset\n",
    "from stardist.models import Config3D, StarDist3D, StarDistData3D\n",
    "\n",
    "np.random.seed(42)\n",
    "lbl_cmap = random_label_cmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c749064-b309-420b-a6f9-e8ad871cd13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training data (for input `X` with associated label masks `Y`) can be provided via lists of numpy arrays, \n",
    "#where each image can have a different size. Alternatively, a single numpy array can also be used if all images have \n",
    "#the same size. Input images can either be three-dimensional (single-channel) or four-dimensional (multi-channel) \n",
    "#arrays, where the channel axis comes last. Label images need to be integer-valued.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0498876c-41c2-435e-9ae1-27919140d517",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sorted(glob('E:/Lien_Lab/Sam/OIC-40_Lipid_Droplet/lipid_data/train/images/*.tif'))\n",
    "Y = sorted(glob('E:/Lien_Lab/Sam/OIC-40_Lipid_Droplet/lipid_data/train/masks/*.tif'))\n",
    "assert all(Path(x).name==Path(y).name for x,y in zip(X,Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3500e868-72f1-433d-90e8-28f4e2728a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(map(imread,X))\n",
    "Y = list(map(imread,Y))\n",
    "n_channel = 1 if X[0].ndim == 3 else X[0].shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752fec44-f41e-418a-9bb3-2a21f1889cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "axis_norm = (0,1,2)   # normalize channels independently\n",
    "# axis_norm = (0,1,2,3) # normalize channels jointly\n",
    "if n_channel > 1:\n",
    "    print(\"Normalizing image channels %s.\" % ('jointly' if axis_norm is None or 3 in axis_norm else 'independently'))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "X = [normalize(x,1,99.8,axis=axis_norm) for x in tqdm(X)]\n",
    "Y = [fill_label_holes(y) for y in tqdm(Y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549773e3-4127-40de-9f74-5ccbf375262a",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Training data consists of pairs of input image and label instances\n",
    "assert len(X) > 1, \"not enough training data\"\n",
    "rng = np.random.RandomState(42)\n",
    "ind = rng.permutation(len(X))\n",
    "n_val = max(1, int(round(0.15 * len(ind))))\n",
    "ind_train, ind_val = ind[:-n_val], ind[-n_val:]\n",
    "X_val, Y_val = [X[i] for i in ind_val]  , [Y[i] for i in ind_val]\n",
    "X_trn, Y_trn = [X[i] for i in ind_train], [Y[i] for i in ind_train] \n",
    "print('number of images: %3d' % len(X))\n",
    "print('- training:       %3d' % len(X_trn))\n",
    "print('- validation:     %3d' % len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993d6868-4af7-46e6-8dae-e83c57c3879c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img_label(img, lbl, img_title=\"image (XY slice)\", lbl_title=\"label (XY slice)\", z=None, **kwargs):\n",
    "    if z is None:\n",
    "        z = img.shape[0] // 2    \n",
    "    fig, (ai,al) = plt.subplots(1,2, figsize=(12,5), gridspec_kw=dict(width_ratios=(1.25,1)))\n",
    "    im = ai.imshow(img[z], cmap='gray', clim=(0,1))\n",
    "    ai.set_title(img_title)    \n",
    "    fig.colorbar(im, ax=ai)\n",
    "    al.imshow(lbl[z], cmap=lbl_cmap)\n",
    "    al.set_title(lbl_title)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf273bd-9d83-4eed-a5f6-cb7b84ababed",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 10\n",
    "img, lbl = X[i], Y[i]\n",
    "assert img.ndim in (3,4)\n",
    "img = img if img.ndim==3 else img[...,:3]\n",
    "plot_img_label(img,lbl)\n",
    "None;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f51efdb-aa90-4c20-a87c-c77c5ac8bca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A StarDist3D model is specified via a Config3D object.\n",
    "print(Config3D.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7b4668-82e6-41f5-ac85-fffbe3fa4598",
   "metadata": {},
   "outputs": [],
   "source": [
    "extents = calculate_extents(Y)\n",
    "anisotropy = tuple(np.max(extents) / extents)\n",
    "print('empirical anisotropy of labeled objects = %s' % str(anisotropy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd0a829-143d-4b47-a1c9-b4eccb4264e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 96 is a good default choice (see 1_data.ipynb)\n",
    "n_rays = 96\n",
    "\n",
    "# Use OpenCL-based computations for data generator during training (requires 'gputools')\n",
    "use_gpu = False and gputools_available()\n",
    "\n",
    "# Predict on subsampled grid for increased efficiency and larger field of view\n",
    "grid = tuple(1 if a > 1.5 else 2 for a in anisotropy)\n",
    "\n",
    "# Use rays on a Fibonacci lattice adjusted for measured anisotropy of the training data\n",
    "rays = Rays_GoldenSpiral(n_rays, anisotropy=anisotropy)\n",
    "\n",
    "conf = Config3D (\n",
    "    rays             = rays,\n",
    "    grid             = grid,\n",
    "    anisotropy       = anisotropy,\n",
    "    use_gpu          = use_gpu,\n",
    "    n_channel_in     = n_channel,\n",
    "    # adjust for your data below (make patch size as large as possible)\n",
    "    train_patch_size = (16,32,32),\n",
    "    train_batch_size = 2,\n",
    ")\n",
    "print(conf)\n",
    "vars(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae89021-041f-4730-9855-1672f3297fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    from csbdeep.utils.tf import limit_gpu_memory\n",
    "    # adjust as necessary: limit GPU memory to be used by TensorFlow to leave some to OpenCL-based computations\n",
    "    limit_gpu_memory(0.8)\n",
    "    # alternatively, try this:\n",
    "    # limit_gpu_memory(None, allow_growth=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae32e739-41ce-4626-90ed-587af47263d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: The trained StarDist3D model will not predict completed shapes for partially visible objects at the image boundary.\n",
    "model = StarDist3D(conf, name='stardist', basedir='models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a7c692-1af1-4892-9edb-e67a521187cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if the neural network has a large enough field of view to see up to the boundary of most objects.\n",
    "median_size = calculate_extents(Y, np.median)\n",
    "fov = np.array(model._axes_tile_overlap('ZYX'))\n",
    "print(f\"median object size:      {median_size}\")\n",
    "print(f\"network field of view :  {fov}\")\n",
    "if any(median_size > fov):\n",
    "    print(\"WARNING: median object size larger than field of view of the neural network.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d065a7-f32b-46bf-b2f7-db7b70485ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_fliprot(img, mask, axis=None): \n",
    "    if axis is None:\n",
    "        axis = tuple(range(mask.ndim))\n",
    "    axis = tuple(axis)\n",
    "            \n",
    "    assert img.ndim>=mask.ndim\n",
    "    perm = tuple(np.random.permutation(axis))\n",
    "    transpose_axis = np.arange(mask.ndim)\n",
    "    for a, p in zip(axis, perm):\n",
    "        transpose_axis[a] = p\n",
    "    transpose_axis = tuple(transpose_axis)\n",
    "    img = img.transpose(transpose_axis + tuple(range(mask.ndim, img.ndim))) \n",
    "    mask = mask.transpose(transpose_axis) \n",
    "    for ax in axis: \n",
    "        if np.random.rand() > 0.5:\n",
    "            img = np.flip(img, axis=ax)\n",
    "            mask = np.flip(mask, axis=ax)\n",
    "    return img, mask \n",
    "\n",
    "def random_intensity_change(img):\n",
    "    img = img*np.random.uniform(0.6,2) + np.random.uniform(-0.2,0.2)\n",
    "    return img\n",
    "\n",
    "def augmenter(x, y):\n",
    "    \"\"\"Augmentation of a single input/label image pair.\n",
    "    x is an input image\n",
    "    y is the corresponding ground-truth label image\n",
    "    \"\"\"\n",
    "    # Note that we only use fliprots along axis=(1,2), i.e. the yx axis \n",
    "    # as 3D microscopy acquisitions are usually not axially symmetric\n",
    "    x, y = random_fliprot(x, y, axis=(1,2))\n",
    "    x = random_intensity_change(x)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d25ebf9-d463-4ac8-a621-e2474c41073e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot some augmented examples\n",
    "img, lbl = X[10],Y[10]\n",
    "plot_img_label(img, lbl)\n",
    "for _ in range(3):\n",
    "    img_aug, lbl_aug = augmenter(img,lbl)\n",
    "    plot_img_label(img_aug, lbl_aug, img_title=\"image augmented (XY slice)\", lbl_title=\"label augmented (XY slice)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f06297-d522-468b-9add-4e16a1aed0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_demo = False\n",
    "\n",
    "if quick_demo:\n",
    "    print (\n",
    "        \"NOTE: This is only for a quick demonstration!\\n\"\n",
    "        \"      Please set the variable 'quick_demo = False' for proper (long) training.\",\n",
    "        file=sys.stderr, flush=True\n",
    "    )\n",
    "    model.train(X_trn, Y_trn, validation_data=(X_val,Y_val), augmenter=augmenter,\n",
    "                epochs=2, steps_per_epoch=5)\n",
    "\n",
    "    print(\"====> Stopping training and loading previously trained demo model from disk.\", file=sys.stderr, flush=True)\n",
    "    model = StarDist3D.from_pretrained('3D_demo')\n",
    "else:\n",
    "    model.train(X_trn, Y_trn, validation_data=(X_val,Y_val), augmenter=augmenter)\n",
    "None;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f73e88a-2053-4602-8457-9d553f7068bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if quick_demo:\n",
    "    # only use a single validation image for demo\n",
    "    model.optimize_thresholds(X_val[:1], Y_val[:1])\n",
    "else:\n",
    "    model.optimize_thresholds(X_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49711a8-d417-45f7-8005-686256b3c17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_val_pred = [model.predict_instances(x, n_tiles=model._guess_n_tiles(x), show_tile_progress=False)[0]\n",
    "              for x in tqdm(X_val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104edeab-9644-42e9-b60b-73e7140cf377",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_img_label(X_val[0],Y_val[0], lbl_title=\"label GT (XY slice)\")\n",
    "plot_img_label(X_val[0],Y_val_pred[0], lbl_title=\"label Pred (XY slice)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed9d1bf-1fd3-4a66-b163-61d074f8ce9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose several IoU thresholds that might be of interest and for each compute matching statistics for the validation data.\n",
    "taus = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "stats = [matching_dataset(Y_val, Y_val_pred, thresh=t, show_progress=False) for t in tqdm(taus)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b5272e-fdf7-441d-82eb-802156c1ec0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats[taus.index(0.7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0d2bdf-cc33-442a-8004-cd39c35af800",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the matching statistics and the number of true/false positives/negatives as a function of the IoU threshold \n",
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize=(15,5))\n",
    "\n",
    "for m in ('precision', 'recall', 'accuracy', 'f1', 'mean_true_score', 'mean_matched_score', 'panoptic_quality'):\n",
    "    ax1.plot(taus, [s._asdict()[m] for s in stats], '.-', lw=2, label=m)\n",
    "ax1.set_xlabel(r'IoU threshold $\\tau$')\n",
    "ax1.set_ylabel('Metric value')\n",
    "ax1.grid()\n",
    "ax1.legend()\n",
    "\n",
    "for m in ('fp', 'tp', 'fn'):\n",
    "    ax2.plot(taus, [s._asdict()[m] for s in stats], '.-', lw=2, label=m)\n",
    "ax2.set_xlabel(r'IoU threshold $\\tau$')\n",
    "ax2.set_ylabel('Number #')\n",
    "ax2.grid()\n",
    "ax2.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533fa6ee-6290-4022-8e42-aae0f9f7d02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddb2910-2ab9-48bf-837f-09809c022e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, unicode_literals, absolute_import, division\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.rcParams[\"image.interpolation\"] = 'none'\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from glob import glob\n",
    "from tifffile import imread\n",
    "from csbdeep.utils import Path, normalize\n",
    "from csbdeep.io import save_tiff_imagej_compatible\n",
    "import skimage as sk\n",
    "import napari\n",
    "import pandas as pd\n",
    "import os\n",
    "from stardist import random_label_cmap\n",
    "from stardist.models import StarDist3D\n",
    "\n",
    "np.random.seed(6)\n",
    "lbl_cmap = random_label_cmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add1553a-ad68-4ef8-b662-142ed62ceee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = sorted(glob('E:/Lien_Lab/Sam/OIC-40_Lipid_Droplet/TIFFs_Split_Channels/CH2_Lipids/*.tif'))\n",
    "imgs = list(map(imread,files))\n",
    "names = os.listdir('E:/Lien_Lab/Sam/OIC-40_Lipid_Droplet/TIFFs_Split_Channels/CH2_Lipids/')\n",
    "path = 'E:/Lien_Lab/Sam/OIC-40_Lipid_Droplet/Predictions/'\n",
    "#print(files[0][:-4])\n",
    "# viewer = napari.view_image(imgs[0], name= 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8864ff-7c64-4b72-85f3-10d82f3d54de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StarDist3D(None, name='stardist', basedir='models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834b8088-8b70-43f7-a50c-f03a4eda2116",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(imgs)):\n",
    "    n_channel = 1 if imgs[i].ndim == 3 else imgs[i].shape[-1]\n",
    "    axis_norm = (0,1,2)   # normalize channels independently\n",
    "    if n_channel > 1:\n",
    "        print(\"Normalizing image channels %s.\" % ('jointly' if axis_norm is None or 2 in axis_norm else 'independently'))\n",
    "    img = normalize(imgs[i], 1,99.8, axis=axis_norm)\n",
    "    labels, details = model.predict_instances(img, n_tiles=model._guess_n_tiles(img), show_tile_progress=False)\n",
    "    save_tiff_imagej_compatible(path+names[i][:-4]+\"_labels.tif\", labels, axes='ZYX')\n",
    "    print(str(i)+\" of \"+str(len(imgs))+\" complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cb50b4-7c03-46ce-beef-4417273e00e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, details = model.predict_instances(img, n_tiles=model._guess_n_tiles(img), show_tile_progress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb59ee35-5e7f-4787-8bf5-2df9a475b902",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sorted(glob('E:/Lien_Lab/Sam/OIC-40_Lipid_Droplet/TIFFs_Split_Channels/CH2_Lipids/*.tif'))\n",
    "X = list(map(imread,X))\n",
    "\n",
    "n_channel = 1 if X[0].ndim == 3 else X[0].shape[-1]\n",
    "axis_norm = (0,1,2)   # normalize channels independently\n",
    "# axis_norm = (0,1,2,3) # normalize channels jointly\n",
    "if n_channel > 1:\n",
    "    print(\"Normalizing image channels %s.\" % ('jointly' if axis_norm is None or 2 in axis_norm else 'independently'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972b5a75-c81f-4277-a488-6a7ae7dbfef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show all test images\n",
    "if True:\n",
    "    fig, ax = plt.subplots(1,3, figsize=(16,16))\n",
    "    for i,(a,x) in enumerate(zip(ax.flat, X)):\n",
    "        a.imshow(x[x.shape[0]//2],cmap='gray')\n",
    "        a.set_title(i)\n",
    "    [a.axis('off') for a in ax.flat]\n",
    "    plt.tight_layout()\n",
    "None;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552dd23a-9f58-44fc-8dd7-c2f9c270200e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you trained your own StarDist model (and optimized its thresholds) via notebook 2_training.ipynb, \n",
    "#then please set demo_model = False below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a44a51b-8493-42f4-97d1-2433f7752226",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_model = False\n",
    "\n",
    "if demo_model:\n",
    "    print (\n",
    "        \"NOTE: This is loading a previously trained demo model!\\n\"\n",
    "        \"      Please set the variable 'demo_model = False' to load your own trained model.\",\n",
    "        file=sys.stderr, flush=True\n",
    "    )\n",
    "    model = StarDist3D.from_pretrained('3D_demo')\n",
    "else:\n",
    "    model = StarDist3D(None, name='stardist', basedir='models')\n",
    "None;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660f736f-287e-462e-a71d-103c77a60045",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = normalize(X[0], 1,99.8, axis=axis_norm)\n",
    "labels, details = model.predict_instances(img, n_tiles=model._guess_n_tiles(img), show_tile_progress=False) #_guess_n_tiles needed for images larger than the training tiles\n",
    "#model.predict_instances(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3afb6c-c8b7-4330-a2d9-5806eefe9738",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,10))\n",
    "z = max(0, img.shape[0] // 2 - 5)\n",
    "plt.subplot(121)\n",
    "plt.imshow((img if img.ndim==3 else img[...,:3])[z], clim=(0,1), cmap='gray')\n",
    "plt.title('Raw image (XY slice)')\n",
    "plt.axis('off')\n",
    "plt.subplot(122)\n",
    "plt.imshow((img if img.ndim==3 else img[...,:3])[z], clim=(0,1), cmap='gray')\n",
    "plt.imshow(labels[z], cmap=lbl_cmap, alpha=0.5)\n",
    "plt.title('Image and predicted labels (XY slice)')\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e857075-1c4f-4965-aa1c-62cccbc26c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the lines in the following cell if you want to save the example image and the predicted label image to disk.\n",
    "save_tiff_imagej_compatible('example_image_03.tif', img, axes='ZYX')\n",
    "save_tiff_imagej_compatible('example_labels_03.tif', labels, axes='ZYX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b453666-234b-467e-8f88-12da01d43a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def example(model, i, show_dist=True):\n",
    "    img = normalize(X[i], 1,99.8, axis=axis_norm)\n",
    "    labels, details = model.predict_instances(img)\n",
    "\n",
    "    plt.figure(figsize=(13,8))\n",
    "    z = img.shape[0] // 2\n",
    "    y = img.shape[1] // 2\n",
    "    img_show = img if img.ndim==3 else img[...,:3]    \n",
    "    plt.subplot(221); plt.imshow(img_show[z],   cmap='gray', clim=(0,1)); plt.axis('off'); plt.title('XY slice')\n",
    "    plt.subplot(222); plt.imshow(img_show[:,y], cmap='gray', clim=(0,1)); plt.axis('off'); plt.title('XZ slice')\n",
    "    plt.subplot(223); plt.imshow(img_show[z],   cmap='gray', clim=(0,1)); plt.axis('off'); plt.title('XY slice')\n",
    "    plt.imshow(labels[z], cmap=lbl_cmap, alpha=0.5)\n",
    "    plt.subplot(224); plt.imshow(img_show[:,y], cmap='gray', clim=(0,1)); plt.axis('off'); plt.title('XZ slice')\n",
    "    plt.imshow(labels[:,y], cmap=lbl_cmap, alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e80fad4-13fe-4b4b-85d6-f5a4036d401e",
   "metadata": {},
   "outputs": [],
   "source": [
    "example(model, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3c9bfa-b208-476c-a328-97f9bc2e502f",
   "metadata": {},
   "outputs": [],
   "source": [
    "example(model, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5291130-7e2b-472b-9987-a53588accea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "example(model, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d723a1b-23ae-4be8-bb86-190f5ac78025",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
